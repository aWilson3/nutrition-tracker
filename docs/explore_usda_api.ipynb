{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USDA FoodData Central Database API\n",
    "Created April 28, 2021<br>\n",
    "Alex Hegeman | ahegem1@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview:<br>https://fdc.nal.usda.gov/about-us.html<br>API documentation:<br>https://fdc.nal.usda.gov/api-guide.html<br>Data documentation:<br>https://fdc.nal.usda.gov/data-documentation.html<br>https://fdc.nal.usda.gov/help.html<br>Historical data downloads:<br>https://fdc.nal.usda.gov/download-datasets.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Sources / Types\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 5 data types (sources) available in the FoodData Central (FDC) database. Some of these data types were previously housed in separate locations.\n",
    "\n",
    "- **Foundation Foods**<span style=\"color:red\">*</span>\n",
    "    - expanded data values and extensive underlying metadata of analysis data including number of samples, sampling location, analytical approaches used, and if appropriate, agricultural information such as genotype and production practices\n",
    "- **Experimental Foods**<span style=\"color:red\">*</span>\n",
    "    - Foods produced, aquired, or studied under unique conditions, such as alternative mangaement systems, experimental genotypes, or research/analytical protocols\n",
    "- **SR Legacy**<span style=\"color:green\">*</span>\n",
    "    - Primary food composition data type in the United States for decades\n",
    "    - comprehensive list of values for food components including nutrients, imputations, and published literature\n",
    "    - April 2018 was the latest and final release of this data\n",
    "- **Food and Nutrient Database for Dietary Studies (FNDDS)**<span style=\"color:green\">*</span>\n",
    "    - nutrient and food component values for foods reported in *What We Eat in America*, by the National health and Nutrition Examination Survey (NHANES)\n",
    "    - released in two-year data cycles\n",
    "- **USDA Global Branded Food Products Database**<span style=\"color:green\">*</span>\n",
    "    - formerly hosted on USDA Food Composition Database website\n",
    "    - public-private partership\n",
    "    - goal is to enhance the open sharing of nutrient data that appear on branded and private label foods and are provided by the food industry\n",
    "\n",
    "<span style=\"color:red\">* According to the documentation, the Foundation and Experimental Foods data will <i>'be  the primary focus of efforts in coming years'</i></span>\n",
    "\n",
    "<span style=\"color:green\">* These data are noted as <i>'well-established and familiar food composition data types'</i> </span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Type Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So after reviewing some of the documentation, my initial thoughts are to keep things simple and just consider the `SR Legacy` data for now.\n",
    "\n",
    "- This data is noted as the primary data source for a long period, and is updated through 2018\n",
    "- It seems like the FNDDS data (at least the nutrition data I'm concerned with right now) is a subset of the SR Legacy data\n",
    "- The Foundational and Experimental are relatively new and probably don't offer much beyong the SR Legacy for my basic needs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:Green\">Questions / Thoughts</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What is the difference between `calculated` and `analytical` derivation types?\n",
    "    1. <span style=\"color:purple\">I think analytical means they did chemistry analysis on food samples and calculated means the values are derived from another measurement (see below question)</span>\n",
    "1. What are the conversion factors and how are they used?\n",
    "    1. Fat, Carb, and Protein factors for kCal energy values (calculated)\n",
    "        1. <span style=\"color:purple\">I think that the kCal value is a multiplication of the values for these macronutrients or somthing similar.</span>\n",
    "    1. Protein from nitrogen for protein values (analytical)\n",
    "        1. <span style=\"color:purple\">This is labeled as analytical in the web search for avocado. Kinda blows up my theory for the first question</span>\n",
    "1. Can use `brandOwner` parameter in the /food/search endpoint to search for specific brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen, Request\n",
    "from urllib.parse import quote, urlencode\n",
    "from explore_funcs import showkeys, showitems\n",
    "import json\n",
    "import pandas as pd\n",
    "# insert valid API key below\n",
    "api_key = ''\n",
    "base_url = 'https://api.nal.usda.gov/fdc/v1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### /food/search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define API endpoint parameters\n",
    "params = dict()\n",
    "params['query'] = \"cabbage\"\n",
    "params['dataType'] = \"SR Legacy\"\n",
    "params['pageSize'] = 20\n",
    "params['api_key'] = api_key\n",
    "# create endpoint url and get search results for 'Avocado'\n",
    "url = base_url + \"/foods/search?\" + urlencode(params)\n",
    "\n",
    "with urlopen(url) as httpcon:\n",
    "    payload = httpcon.read().decode()\n",
    "\n",
    "av = json.loads(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " totalHits <class 'int'> \n",
      " currentPage <class 'int'> \n",
      " totalPages <class 'int'> \n",
      " pageList <class 'list'> 1\n",
      "     <class 'int'> 1\n",
      " foodSearchCriteria <class 'dict'> 8\n",
      "     dataType <class 'list'> 1\n",
      "         <class 'str'> 1\n",
      "     query <class 'str'> 7\n",
      "     generalSearchInput <class 'str'> 7\n",
      "     pageNumber <class 'int'> \n",
      "     numberOfResultsPerPage <class 'int'> \n",
      "     pageSize <class 'int'> \n",
      "     requireAllWords <class 'bool'> \n",
      "     foodTypes <class 'list'> 1\n",
      "         <class 'str'> 1\n",
      " foods <class 'list'> 4\n",
      "     <foods[0] dict keys>\n",
      "         fdcId <class 'int'> \n",
      "         description <class 'str'> 12\n",
      "         lowercaseDescription <class 'str'> 12\n",
      "         commonNames <class 'str'> 0\n",
      "         additionalDescriptions <class 'str'> 0\n",
      "         dataType <class 'str'> 9\n",
      "         ndbNumber <class 'int'> \n",
      "         publishedDate <class 'str'> 10\n",
      "         foodCategory <class 'str'> 13\n",
      "         allHighlightFields <class 'str'> 0\n",
      "         score <class 'float'> \n",
      "         foodNutrients <class 'list'> 41\n",
      "             <foodNutrients[0] dict keys>\n",
      "                 nutrientId <class 'int'> \n",
      "                 nutrientName <class 'str'> 10\n",
      "                 nutrientNumber <class 'str'> 3\n",
      "                 unitName <class 'str'> 2\n",
      "                 derivationCode <class 'str'> 1\n",
      "                 derivationDescription <class 'str'> 95\n",
      "                 value <class 'float'> \n",
      " aggregations <class 'dict'> 2\n",
      "     dataType <class 'dict'> 3\n",
      "         Branded <class 'int'> \n",
      "         Survey (FNDDS) <class 'int'> \n",
      "         SR Legacy <class 'int'> \n",
      "     nutrients <class 'dict'> 0\n"
     ]
    }
   ],
   "source": [
    "# show structure of json results\n",
    "showkeys(av)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Ok, so it looks like we have a handful of meta fields and one field with the actual results.<br><br>\n",
    "Metadata includes how many results are returned for the specified data type(s), number of pages, page information, search criteria, and number of matching results from other data types (not necessarily included\n",
    "in the request).<br><br>\n",
    "The food search results are in the 'foods' field, and it looks like we got 4 results. Let's take a look to see which result we may be most interested in\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Cabbage, kimchi\n",
      "1 Cabbage, raw\n",
      "2 Cabbage, mustard, salted\n",
      "3 Cabbage, napa, cooked\n",
      "4 Cabbage, red, raw\n",
      "5 Cabbage, savoy, raw\n",
      "6 Cabbage, chinese (pak-choi), raw\n",
      "7 Cabbage, chinese (pe-tsai), raw\n",
      "8 Cabbage, japanese style, fresh, pickled\n",
      "9 Cabbage, common, cooked, boiled, drained, with salt\n",
      "10 Cabbage, cooked, boiled, drained, without salt\n",
      "11 Cabbage, red, cooked, boiled, drained, with salt\n",
      "12 Cabbage, savoy, cooked, boiled, drained, with salt\n",
      "13 Cabbage, red, cooked, boiled, drained, without salt\n",
      "14 Cabbage, savoy, cooked, boiled, drained, without salt\n",
      "15 Cabbage, chinese (pak-choi), cooked, boiled, drained, with salt\n",
      "16 Cabbage, chinese (pe-tsai), cooked, boiled, drained, with salt\n",
      "17 Cabbage, common (danish, domestic, and pointed types), stored, raw\n",
      "18 Cabbage, chinese (pak-choi), cooked, boiled, drained, without salt\n",
      "19 Cabbage, chinese (pe-tsai), cooked, boiled, drained, without salt\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(av['foods'])):\n",
    "    print(i, av['foods'][i]['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Food: Fish, salmon, sockeye, cooked, dry heat\n",
      "Category: Finfish and Shellfish Products\n",
      "FDC Id: 173692\n",
      "NDB Id: 15086\n",
      "\n",
      "\n",
      "1222 - 513  Alanine:          1.65 G\n",
      "1220 - 511  Arginine:          1.72 G\n",
      "1007 - 207  Ash:          1.5 G\n",
      "1223 - 514  Aspartic acid:          2.71 G\n",
      "1087 - 301  Calcium, Ca:          11.0 MG\n",
      "1253 - 601  Cholesterol:          61.0 MG\n",
      "1180 - 421  Choline, total:          113 MG\n",
      "1098 - 312  Copper, Cu:          0.076 MG\n",
      "1216 - 507  Cystine:          0.295 G\n",
      "1008 - 208  Energy:          156 KCAL\n",
      "1062 - 268  Energy:          653 kJ\n",
      "1292 - 645  Fatty acids, total monounsaturated:          1.86 G\n",
      "1293 - 646  Fatty acids, total polyunsaturated:          1.33 G\n",
      "1258 - 606  Fatty acids, total saturated:          0.969 G\n",
      "1257 - 605  Fatty acids, total trans:          0.023 G\n",
      "1190 - 435  Folate, DFE:          7.0 UG\n",
      "1187 - 432  Folate, food:          7.0 UG\n",
      "1177 - 417  Folate, total:          7.0 UG\n",
      "1224 - 515  Glutamic acid:          3.9 G\n",
      "1225 - 516  Glycine:          1.27 G\n",
      "1221 - 512  Histidine:          0.711 G\n",
      "1089 - 303  Iron, Fe:          0.52 MG\n",
      "1212 - 503  Isoleucine:          1.27 G\n",
      "1213 - 504  Leucine:          2.18 G\n",
      "1214 - 505  Lysine:          2.57 G\n",
      "1274 - 625  MUFA 14:1:          0.004 G\n",
      "1275 - 626  MUFA 16:1:          0.164 G\n",
      "1323 - 687  MUFA 17:1:          0.015 G\n",
      "1268 - 617  MUFA 18:1:          0.843 G\n",
      "1277 - 628  MUFA 20:1:          0.447 G\n",
      "1279 - 630  MUFA 22:1:          0.374 G\n",
      "1312 - 671  MUFA 24:1 c:          0.017 G\n",
      "1090 - 304  Magnesium, Mg:          36.0 MG\n",
      "1101 - 315  Manganese, Mn:          0.013 MG\n",
      "1215 - 506  Methionine:          0.858 G\n",
      "1167 - 406  Niacin:          10.1 MG\n",
      "1269 - 618  PUFA 18:2:          0.19 G\n",
      "1270 - 619  PUFA 18:3:          0.058 G\n",
      "1276 - 627  PUFA 18:4:          0.064 G\n",
      "1313 - 672  PUFA 20:2 n-6 c,c:          0.019 G\n",
      "1325 - 689  PUFA 20:3:          0.017 G\n",
      "1271 - 620  PUFA 20:4:          0.02 G\n",
      "1411 - 858  PUFA 22:4:          0.003 G\n",
      "1280 - 631  PUFA 22:5 n-3 (DPA):          0.093 G\n",
      "1272 - 621  PUFA 22:6 n-3 (DHA):          0.56 G\n",
      "1278 - 629  PUFA 2:5 n-3 (EPA):          0.299 G\n",
      "1170 - 410  Pantothenic acid:          1.27 MG\n",
      "1217 - 508  Phenylalanine:          1.09 G\n",
      "1091 - 305  Phosphorus, P:          305 MG\n",
      "1092 - 306  Potassium, K:          436 MG\n",
      "1226 - 517  Proline:          0.979 G\n",
      "1003 - 203  Protein:          26.5 G\n",
      "1105 - 319  Retinol:          58.0 UG\n",
      "1166 - 405  Riboflavin:          0.246 MG\n",
      "1262 - 610  SFA 10:0:          0.001 G\n",
      "1263 - 611  SFA 12:0:          0.003 G\n",
      "1264 - 612  SFA 14:0:          0.15 G\n",
      "1299 - 652  SFA 15:0:          0.018 G\n",
      "1265 - 613  SFA 16:0:          0.653 G\n",
      "1300 - 653  SFA 17:0:          0.013 G\n",
      "1266 - 614  SFA 18:0:          0.124 G\n",
      "1267 - 615  SFA 20:0:          0.006 G\n",
      "1273 - 624  SFA 22:0:          0.001 G\n",
      "1103 - 317  Selenium, Se:          35.5 UG\n",
      "1227 - 518  Serine:          1.06 G\n",
      "1093 - 307  Sodium, Na:          92.0 MG\n",
      "1165 - 404  Thiamin:          0.157 MG\n",
      "1211 - 502  Threonine:          1.25 G\n",
      "1125 - 341  Tocopherol, beta:          0.01 MG\n",
      "1127 - 343  Tocopherol, delta:          0.22 MG\n",
      "1126 - 342  Tocopherol, gamma:          0.19 MG\n",
      "1004 - 204  Total lipid (fat):          5.57 G\n",
      "1210 - 501  Tryptophan:          0.335 G\n",
      "1218 - 509  Tyrosine:          1.21 G\n",
      "1219 - 510  Valine:          1.46 G\n",
      "1104 - 318  Vitamin A, IU:          193 IU\n",
      "1106 - 320  Vitamin A, RAE:          58.0 UG\n",
      "1178 - 418  Vitamin B-12:          4.47 UG\n",
      "1175 - 415  Vitamin B-6:          0.827 MG\n",
      "1114 - 328  Vitamin D (D2 + D3):          16.7 UG\n",
      "1110 - 324  Vitamin D (D2 + D3), International Units:          670 IU\n",
      "1112 - 326  Vitamin D3 (cholecalciferol):          16.7 UG\n",
      "1109 - 323  Vitamin E (alpha-tocopherol):          0.99 MG\n",
      "1183 - 428  Vitamin K (Menaquinone-4):          0.4 UG\n",
      "1185 - 430  Vitamin K (phylloquinone):          0.1 UG\n",
      "1051 - 255  Water:          67.3 G\n",
      "1095 - 309  Zinc, Zn:          0.55 MG\n"
     ]
    }
   ],
   "source": [
    "# I am interested in the whole raw avocado fruit.\n",
    "# We'll pick the California variety for further exploration\n",
    "av_ca = av['foods'][2]\n",
    "# get id numbers\n",
    "av_ca_desc = av_ca['description']\n",
    "av_ca_id_fdc = av_ca['fdcId']\n",
    "av_ca_id_ndb = av_ca['ndbNumber']\n",
    "av_ca_cateogry = av_ca['foodCategory']\n",
    "# get non-zero nutrient values\n",
    "nutrient_list = []\n",
    "for n in av_ca['foodNutrients']:\n",
    "    if n['value'] > 0:\n",
    "        nutrient_list.append(n)\n",
    "# display information\n",
    "print(\"Food:\", av_ca_desc)\n",
    "print(\"Category:\", av_ca_cateogry)\n",
    "print(\"FDC Id:\", str(av_ca_id_fdc))\n",
    "print(\"NDB Id:\", str(av_ca_id_ndb))\n",
    "print(\"\\n\")\n",
    "\n",
    "nutrient_list.sort(key=lambda x: x['nutrientName'])\n",
    "for n in nutrient_list:\n",
    "    print(\"{} - {}  {}:{}{} {}\".format(n['nutrientId'], n['nutrientNumber'] , n['nutrientName'], \" \"*10, n['value'], n['unitName']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Cool. Looks like a lot of good nutrient data. Something I don't see here is the portion sizes. Now that we have the FDC Id, we can make a request to the 'details' endpoint and see what additional information we can get there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### /food/{fdcId}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The documentation says this endpoint reutrns details for a given food, as identified by that food's FDC Id number. We retrieved this id from the /food/search endpoint above. The documentation also states that if we want nutrient data for the given food, we must specify the nutrient number(s) in the request. However, only up to 25 nutrient numbers may be provided. So if we want more than that, it seems like maybe the search endpoint is going to be a better bet. But let's see what we've got here.\n",
    "<br>\n",
    "<div style=\"color:blue\">EDIT -- The details endpoint actually returns all nutrients by default. The nutrient parameter is used to <i>reduce</i> the number of nutrients returned to only those specified</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create endpoint url and retrieve detail data\n",
    "# will limit nutrients returned to protein and calcium for this example\n",
    "params_details = dict()\n",
    "params_details['nutrients'] = '203,301,313' # 313 is not returned, presumably b/c avocados don't contain Fluoride\n",
    "params_details['api_key'] = api_key\n",
    "\n",
    "url_details = base_url + \"/food/\" + str(av_ca_id_fdc) + \"?\" + urlencode(params_details)\n",
    "\n",
    "with urlopen(url_details) as httpcon:\n",
    "    payload = httpcon.read().decode()\n",
    "\n",
    "av_details = json.loads(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " fdcId <class 'int'> \n",
      " description <class 'str'> 25\n",
      " publicationDate <class 'str'> 8\n",
      " foodNutrients <class 'list'> 2\n",
      "     <foodNutrients[0] dict keys>\n",
      "         type <class 'str'> 12\n",
      "         nutrient <class 'dict'> 5\n",
      "             id <class 'int'> \n",
      "             number <class 'str'> 3\n",
      "             name <class 'str'> 7\n",
      "             rank <class 'int'> \n",
      "             unitName <class 'str'> 1\n",
      "         foodNutrientDerivation <class 'dict'> 4\n",
      "             id <class 'int'> \n",
      "             code <class 'str'> 1\n",
      "             description <class 'str'> 10\n",
      "             foodNutrientSource <class 'dict'> 3\n",
      "                 id <class 'int'> \n",
      "                 code <class 'str'> 1\n",
      "                 description <class 'str'> 37\n",
      "         id <class 'int'> \n",
      "         amount <class 'float'> \n",
      "         dataPoints <class 'int'> \n",
      "         max <class 'float'> \n",
      "         min <class 'float'> \n",
      " foodPortions <class 'list'> 3\n",
      "     <foodPortions[0] dict keys>\n",
      "         id <class 'int'> \n",
      "         dataPoints <class 'int'> \n",
      "         gramWeight <class 'float'> \n",
      "         sequenceNumber <class 'int'> \n",
      "         amount <class 'float'> \n",
      "         modifier <class 'str'> 28\n",
      "         measureUnit <class 'dict'> 3\n",
      "             id <class 'int'> \n",
      "             name <class 'str'> 12\n",
      "             abbreviation <class 'str'> 12\n",
      " dataType <class 'str'> 9\n",
      " foodClass <class 'str'> 9\n",
      " scientificName <class 'str'> 16\n",
      " foodComponents <class 'list'> 0\n",
      "     Empty List - []\n",
      " foodAttributes <class 'list'> 0\n",
      "     Empty List - []\n",
      " nutrientConversionFactors <class 'list'> 2\n",
      "     <nutrientConversionFactors[0] dict keys>\n",
      "         id <class 'int'> \n",
      "         proteinValue <class 'float'> \n",
      "         fatValue <class 'float'> \n",
      "         carbohydrateValue <class 'float'> \n",
      "         type <class 'str'> 24\n",
      "         name <class 'str'> 24\n",
      " inputFoods <class 'list'> 0\n",
      "     Empty List - []\n",
      " ndbNumber <class 'int'> \n",
      " isHistoricalReference <class 'bool'> \n",
      " foodCategory <class 'dict'> 3\n",
      "     id <class 'int'> \n",
      "     code <class 'str'> 4\n",
      "     description <class 'str'> 23\n"
     ]
    }
   ],
   "source": [
    "# investigate json results\n",
    "showkeys(av_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"type\": \"FoodNutrient\",\n",
      "        \"nutrient\": {\n",
      "            \"id\": 1003,\n",
      "            \"number\": \"203\",\n",
      "            \"name\": \"Protein\",\n",
      "            \"rank\": 600,\n",
      "            \"unitName\": \"g\"\n",
      "        },\n",
      "        \"foodNutrientDerivation\": {\n",
      "            \"id\": 1,\n",
      "            \"code\": \"A\",\n",
      "            \"description\": \"Analytical\",\n",
      "            \"foodNutrientSource\": {\n",
      "                \"id\": 1,\n",
      "                \"code\": \"1\",\n",
      "                \"description\": \"Analytical or derived from analytical\"\n",
      "            }\n",
      "        },\n",
      "        \"id\": 1632893,\n",
      "        \"amount\": 1.96,\n",
      "        \"dataPoints\": 30,\n",
      "        \"max\": 3.0,\n",
      "        \"min\": 1.53\n",
      "    },\n",
      "    {\n",
      "        \"type\": \"FoodNutrient\",\n",
      "        \"nutrient\": {\n",
      "            \"id\": 1087,\n",
      "            \"number\": \"301\",\n",
      "            \"name\": \"Calcium, Ca\",\n",
      "            \"rank\": 5300,\n",
      "            \"unitName\": \"mg\"\n",
      "        },\n",
      "        \"foodNutrientDerivation\": {\n",
      "            \"id\": 1,\n",
      "            \"code\": \"A\",\n",
      "            \"description\": \"Analytical\",\n",
      "            \"foodNutrientSource\": {\n",
      "                \"id\": 1,\n",
      "                \"code\": \"1\",\n",
      "                \"description\": \"Analytical or derived from analytical\"\n",
      "            }\n",
      "        },\n",
      "        \"id\": 1632842,\n",
      "        \"amount\": 13.0,\n",
      "        \"dataPoints\": 24,\n",
      "        \"max\": 19.0,\n",
      "        \"min\": 8.0\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(av_details['foodNutrients'], indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "So it looks like the nutrient data is pretty similar to that available in the search endpoint. However, one noteable difference is that the details data includes the `min`, `max`, and `dataPoints` values for a nutrient when available.\n",
    "<br><br>Let's look at some of the other data available.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FinalFood\n",
      "Persea americana\n",
      "{'id': 9, 'code': '0900', 'description': 'Fruits and Fruit Juices'}\n"
     ]
    }
   ],
   "source": [
    "print(av_details['foodClass'])\n",
    "print(av_details['scientificName'])\n",
    "print(av_details['foodCategory'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"id\": 89229,\n",
      "        \"dataPoints\": 22,\n",
      "        \"gramWeight\": 136.0,\n",
      "        \"sequenceNumber\": 2,\n",
      "        \"amount\": 1.0,\n",
      "        \"modifier\": \"fruit, without skin and seed\",\n",
      "        \"measureUnit\": {\n",
      "            \"id\": 9999,\n",
      "            \"name\": \"undetermined\",\n",
      "            \"abbreviation\": \"undetermined\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"id\": 89228,\n",
      "        \"gramWeight\": 230.0,\n",
      "        \"sequenceNumber\": 1,\n",
      "        \"amount\": 1.0,\n",
      "        \"modifier\": \"cup, pureed\",\n",
      "        \"measureUnit\": {\n",
      "            \"id\": 9999,\n",
      "            \"name\": \"undetermined\",\n",
      "            \"abbreviation\": \"undetermined\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"id\": 89230,\n",
      "        \"gramWeight\": 50.0,\n",
      "        \"sequenceNumber\": 3,\n",
      "        \"amount\": 1.0,\n",
      "        \"modifier\": \"NLEA serving\",\n",
      "        \"measureUnit\": {\n",
      "            \"id\": 9999,\n",
      "            \"name\": \"undetermined\",\n",
      "            \"abbreviation\": \"undetermined\"\n",
      "        }\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(av_details['foodPortions'], indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "So it seems like the `foodPortions` field may be the biggest value add from the details endpoint. This contains conversions from grams to other commonly-used measurement units, which will allow a calculation of nutrients based off the 100-gram baselines given in the nutrient information.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### /foods/list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.nal.usda.gov/fdc/v1/foods/list?dataType=SR+Legacy&pageSize=3&api_key=jUaOrG7dHdKMiz71EWhzJAIHwEldl2Lu9O9viofQ\n"
     ]
    }
   ],
   "source": [
    "params_list = dict()\n",
    "# params_list['nutrients'] = '203,301'\n",
    "params_list['dataType'] = 'SR Legacy'\n",
    "params_list['pageSize'] = 3\n",
    "params_list['api_key'] = api_key\n",
    "\n",
    "url_list = base_url + \"/foods/list?\" + urlencode(params_list)\n",
    "print(url_list)\n",
    "\n",
    "with urlopen(url_list) as httpcon:\n",
    "    payload = httpcon.read().decode()\n",
    "\n",
    "food_list = json.loads(payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "So this could be helpful if you wanted to return a top 10 list of something ranked by a certain nutrient.\n",
    "It will return a list of foods and you can specify how many to return and how the query should be sorted.\n",
    "<br>\n",
    "<div style=\"color:red\">EDIT -- mmm nevermind. After reviewing documentation it looks like we can only sort on name/description, id, or published date. Not very useful for me</div>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play with Search Operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oil, avocado\n",
      "Avocados, raw, California\n",
      "Avocados, raw, Florida\n",
      "Avocados, raw, all commercial varieties\n"
     ]
    }
   ],
   "source": [
    "# original query from above\n",
    "params = dict()\n",
    "params['query'] = \"Avocado\"\n",
    "params['dataType'] = \"SR Legacy\"\n",
    "params['pageSize'] = 4\n",
    "params['api_key'] = api_key\n",
    "# create endpoint url and get search results for 'Avocado'\n",
    "url = base_url + \"/foods/search?\" + urlencode(params)\n",
    "\n",
    "with urlopen(url) as httpcon:\n",
    "    payload = httpcon.read().decode()\n",
    "\n",
    "av = json.loads(payload)\n",
    "\n",
    "for food in av['foods']:\n",
    "    print(food['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avocados, raw, California\n",
      "Avocados, raw, Florida\n",
      "Avocados, raw, all commercial varieties\n"
     ]
    }
   ],
   "source": [
    "# updated query to exclude results containing 'oil' in description\n",
    "params['query'] = \"Avocado -oil\"\n",
    "url = base_url + \"/foods/search?\" + urlencode(params)\n",
    "\n",
    "with urlopen(url) as httpcon:\n",
    "    payload = httpcon.read().decode()\n",
    "\n",
    "av = json.loads(payload)\n",
    "\n",
    "for food in av['foods']:\n",
    "    print(food['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.nal.usda.gov/fdc/v1/foods/search?query=%2B%2Aberries%2A+%2Braw&dataType=SR+Legacy&pageSize=&api_key=jUaOrG7dHdKMiz71EWhzJAIHwEldl2Lu9O9viofQ\n",
      "Blackberries, raw\n",
      "Blueberries, raw\n",
      "Cranberries, raw\n",
      "Elderberries, raw\n",
      "Gooseberries, raw\n",
      "Mulberries, raw\n",
      "Oheloberries, raw\n",
      "Raspberries, raw\n",
      "Strawberries, raw\n",
      "Cloudberries, raw (Alaska Native)\n",
      "Huckleberries, raw (Alaska Native)\n",
      "Salmonberries, raw (Alaska Native)\n",
      "Blackberries, wild, raw (Alaska Native)\n",
      "Blueberries, wild, raw (Alaska Native)\n",
      "Groundcherries, (cape-gooseberries or poha), raw\n",
      "Cranberries, wild, bush, raw (Alaska Native)\n"
     ]
    }
   ],
   "source": [
    "# find all results with descriptions containing 'berries' and 'raw'\n",
    "params['query'] = '+*berries* +raw'\n",
    "params['pageSize'] = \"\"\n",
    "url = base_url + \"/foods/search?\" + urlencode(params)\n",
    "print(url)\n",
    "with urlopen(url) as httpcon:\n",
    "    payload = httpcon.read().decode()\n",
    "\n",
    "av = json.loads(payload)\n",
    "\n",
    "for food in av['foods']:\n",
    "    print(food['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.nal.usda.gov/fdc/v1/foods/search?query=commonNames%3A%22hamburger%22&dataType=SR+Legacy&pageSize=&api_key=jUaOrG7dHdKMiz71EWhzJAIHwEldl2Lu9O9viofQ\n",
      "Beef, Australian, imported, grass-fed, ground, 85% lean / 15% fat, raw\n",
      "Beef, grass-fed, ground, raw\n",
      "Beef, ground, 70% lean meat / 30% fat, crumbles, cooked, pan-browned\n",
      "Beef, ground, 70% lean meat / 30% fat, loaf, cooked, baked\n",
      "Beef, ground, 70% lean meat / 30% fat, patty cooked, pan-broiled\n",
      "Beef, ground, 70% lean meat / 30% fat, patty, cooked, broiled\n",
      "Beef, ground, 70% lean meat / 30% fat, raw\n",
      "Beef, ground, 75% lean meat / 25% fat, crumbles, cooked, pan-browned\n",
      "Beef, ground, 75% lean meat / 25% fat, loaf, cooked, baked\n",
      "Beef, ground, 75% lean meat / 25% fat, patty, cooked, broiled\n",
      "Beef, ground, 75% lean meat / 25% fat, patty, cooked, pan-broiled\n",
      "Beef, ground, 75% lean meat / 25% fat, raw\n",
      "Beef, ground, 80% lean meat / 20% fat, crumbles, cooked, pan-browned\n",
      "Beef, ground, 80% lean meat / 20% fat, loaf, cooked, baked\n",
      "Beef, ground, 80% lean meat / 20% fat, patty, cooked, broiled\n",
      "Beef, ground, 80% lean meat / 20% fat, patty, cooked, pan-broiled\n",
      "Beef, ground, 80% lean meat / 20% fat, raw\n",
      "Beef, ground, 85% lean meat / 15% fat, loaf, cooked, baked\n",
      "Beef, ground, 85% lean meat / 15% fat, patty, cooked, pan-broiled\n",
      "Beef, ground, 85% lean meat / 15% fat, raw (Includes foods for USDA's Food Distribution Program)\n",
      "Beef, ground, 90% lean meat / 10% fat, crumbles, cooked, pan-browned\n",
      "Beef, ground, 90% lean meat / 10% fat, loaf, cooked, baked\n",
      "Beef, ground, 90% lean meat / 10% fat, patty, cooked, broiled\n",
      "Beef, ground, 90% lean meat / 10% fat, patty, cooked, pan-broiled\n",
      "Beef, ground, 90% lean meat / 10% fat, raw\n",
      "Beef, ground, 93% lean meat / 7% fat, crumbles, cooked, pan-browned\n",
      "Beef, ground, 93% lean meat / 7% fat, loaf, cooked, baked\n",
      "Beef, ground, 93% lean meat / 7% fat, patty, cooked, broiled\n",
      "Beef, ground, 93% lean meat / 7% fat, raw\n",
      "Beef, ground, 93% lean meat /7% fat, patty, cooked, pan-broiled\n",
      "Beef, ground, 95% lean meat / 5% fat, crumbles, cooked, pan-browned\n",
      "Beef, ground, 95% lean meat / 5% fat, loaf, cooked, baked\n",
      "Beef, ground, 95% lean meat / 5% fat, patty, cooked, broiled\n",
      "Beef, ground, 95% lean meat / 5% fat, patty, cooked, pan-broiled\n",
      "Beef, ground, 95% lean meat / 5% fat, raw\n",
      "Beef, ground, 97% lean meat / 3% fat, crumbles, cooked, pan-browned\n",
      "Beef, ground, 97% lean meat / 3% fat, loaf, cooked, baked\n",
      "Beef, ground, 97% lean meat / 3% fat, patty, cooked, broiled\n",
      "Beef, ground, 97% lean meat / 3% fat, raw\n",
      "Beef, ground, 97% lean meat /3% fat, patty, cooked, pan-broiled\n",
      "Beef, ground, patties, frozen, cooked, broiled\n",
      "Beef, ground, unspecified fat content, cooked\n",
      "Beef, ground, 85% lean meat / 15% fat, crumbles, cooked, pan-browned\n",
      "Beef, ground, 85% lean meat / 15% fat, patty, cooked, broiled\n"
     ]
    }
   ],
   "source": [
    "# find all results with common names containing 'burger'\n",
    "params['query'] = 'commonNames:\"hamburger\"'\n",
    "params['pageSize'] = \"\"\n",
    "url = base_url + \"/foods/search?\" + urlencode(params)\n",
    "print(url)\n",
    "with urlopen(url) as httpcon:\n",
    "    payload = httpcon.read().decode()\n",
    "\n",
    "av = json.loads(payload)\n",
    "\n",
    "for food in av['foods']:\n",
    "    print(food['description'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
